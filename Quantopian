import quantopian.algorithm as algo
import quantopian.optimize as opt
from quantopian.pipeline import Pipeline
from quantopian.pipeline.factors import SimpleMovingAverage

from quantopian.pipeline.filters import QTradableStocksUS
from quantopian.pipeline.experimental import risk_loading_pipeline

from quantopian.pipeline.data.psychsignal import stocktwits
from quantopian.pipeline.data import Fundamentals

#Datasets
from quantopian.pipeline.data.psychsignal import twitter_withretweets
from quantopian.pipeline.data.sentdex import sentiment
from quantopian.pipeline.data.factset.estimates import ConsensusRecomendations

# Constraint Parameters
MAX_GROSS_LEVERAGE = 1.0
TOTAL_POSITIONS = 600


MAX_SHORT_POSITION_SIZE = 2.5 / TOTAL_POSITIONS
MAX_LONG_POSITION_SIZE = 2.5 / TOTAL_POSITIONS


def initialize(context):
   
    algo.attach_pipeline(make_pipeline(), 'long_short_equity_template')

    algo.attach_pipeline(risk_loading_pipeline(), 'risk_factors')

    # Schedule our rebalance function
    algo.schedule_function(func=rebalance,
                           date_rule=algo.date_rules.week_start(),
                           time_rule=algo.time_rules.market_open(hours=0, minutes=30),
                           half_days=True)

    # Record our portfolio variables at the end of day
    algo.schedule_function(func=record_vars,
                           date_rule=algo.date_rules.every_day(),
                           time_rule=algo.time_rules.market_close(),
                           half_days=True)


def make_pipeline():
   
    # The factors we create here are based on fundamentals data and a moving
    # average of sentiment data
    value = Fundamentals.ebit.latest / Fundamentals.enterprise_value.latest
    quality = Fundamentals.roe.latest
    sentiment_score = SimpleMovingAverage(inputs=[stocktwits.bull_minus_bear],window_length=3,)
    #Puntaje para twitter
    twitter_score = SimpleMovingAverage(inputs=[twitter_withretweets.bull_bear_msg_ratio],window_length=3,)    
    #Puntaje noticias
    news_score = SimpleMovingAverage(inputs=[sentiment.sentiment_signal], window_length=5)

    # Total revenue value.
    total_revenue = Fundamentals.total_revenue.latest

    #Crecimiento sostenible
    growth = Fundamentals.sustainable_growth_rate.latest
   
    #Margen operacional
    operation_margin = Fundamentals.operation_margin.latest
   
    #Margen bruto de utilidad
    net_margin = Fundamentals.net_margin.latest

    rec_corredor = SimpleMovingAverage( inputs = [ConsensusRecommendations.total], window_length=3, )

    universe = QTradableStocksUS()
   
    # We winsorize our factor values in order to lessen the impact of outliers

    value_winsorized = value.winsorize(min_percentile=0.17, max_percentile=0.83)
    quality_winsorized = quality.winsorize(min_percentile=0.17, max_percentile=0.83)
    sentiment_score_winsorized = sentiment_score.winsorize(min_percentile=0.17,                                                                             max_percentile=0.83)
    twitter_score_winsorized = twitter_score.winsorize(min_percentile=0.17, max_percentile=0.83)
    news_score_winsorized = news_score.winsorize(min_percentile=0.17, max_percentile=0.83)
    total_revenue_winsorized = total_revenue.winsorize(min_percentile=0.17, max_percentile=0.83)
    growth_winsorized = growth.winsorize(min_percentile=0.17, max_percentile=0.83)
    operation_margin_winsorized = operation_margin.winsorize(min_percentile=0.17, max_percentile=0.83)
    net_margin_winsorized = net_margin.winsorize(min_percentile=0.17, max_percentile=0.83)
    rec_corredor_winsorized = rec_corredor.winsorize(min_percentile=0.17, max_percentile=0.83)

    # Here we combine our winsorized factors, z-scoring them to equalize their influence
    combined_factor = (
        1*value_winsorized.zscore()  
        + 6*quality_winsorized.zscore()
        + 1*sentiment_score_winsorized.zscore()
        + 5*twitter_score_winsorized.zscore()
        + 1*news_score_winsorized.zscore()
        + 6*growth_winsorized.zscore()
        + 1*operation_margin_winsorized.zscore()
        + 1*net_margin_winsorized.zscore()
        + 6*total_revenue_winsorized.zscore()
        + 9*rec_corredor_winsorized.zscore()
    )

    # Build Filters representing the top and bottom baskets of stocks by our
    # combined ranking system. We'll use these as our tradeable universe each
    # day.
    longs = combined_factor.top(TOTAL_POSITIONS//2, mask=universe)
    shorts = combined_factor.bottom(TOTAL_POSITIONS//2, mask=universe)

    # The final output of our pipeline should only include
    # the top/bottom 300 stocks by our criteria
    long_short_screen = (longs | shorts)

    # Create pipeline
    pipe = Pipeline(
        columns={
            'longs': longs,
            'shorts': shorts,
            'combined_factor': combined_factor
        },
        screen=long_short_screen
    )
    return pipe


def before_trading_start(context, data):
 
    context.pipeline_data = algo.pipeline_output('long_short_equity_template')

    # This dataframe will contain all of our risk loadings
    context.risk_loadings = algo.pipeline_output('risk_factors')


def record_vars(context, data):
    """
    A function scheduled to run every day at market close in order to record
    strategy information.

    Parameters
    ----------
    context : AlgorithmContext
        See description above.
    data : BarData
        See description above.
    """
    # Plot the number of positions over time.
    algo.record(num_positions=len(context.portfolio.positions))


# Called at the start of every month in order to rebalance
# the longs and shorts lists
def rebalance(context, data):
    """
    A function scheduled to run once every Monday at 10AM ET in order to
    rebalance the longs and shorts lists.

    Parameters
    ----------
    context : AlgorithmContext
        See description above.
    data : BarData
        See description above.
    """
    # Retrieve pipeline output
    pipeline_data = context.pipeline_data

    risk_loadings = context.risk_loadings

    # Here we define our objective for the Optimize API. We have
    # selected MaximizeAlpha because we believe our combined factor
    # ranking to be proportional to expected returns. This routine
    # will optimize the expected return of our algorithm, going
    # long on the highest expected return and short on the lowest.
    objective = opt.MaximizeAlpha(pipeline_data.combined_factor)

    # Define the list of constraints
    constraints = []
    # Constrain our maximum gross leverage
    constraints.append(opt.MaxGrossExposure(MAX_GROSS_LEVERAGE))

    # Require our algorithm to remain dollar neutral
    constraints.append(opt.DollarNeutral())

    # Add the RiskModelExposure constraint to make use of the
    # default risk model constraints
    neutralize_risk_factors = opt.experimental.RiskModelExposure(
        risk_model_loadings=risk_loadings,
        version=0
    )
    constraints.append(neutralize_risk_factors)

    # With this constraint we enforce that no position can make up
    # greater than MAX_SHORT_POSITION_SIZE on the short side and
    # no greater than MAX_LONG_POSITION_SIZE on the long side. This
    # ensures that we do not overly concentrate our portfolio in
    # one security or a small subset of securities.
    constraints.append(
        opt.PositionConcentration.with_equal_bounds(
            min=-MAX_SHORT_POSITION_SIZE,
            max=MAX_LONG_POSITION_SIZE
        ))

    # Put together all the pieces we defined above by passing
    # them into the algo.order_optimal_portfolio function. This handles
    # all of our ordering logic, assigning appropriate weights
    # to the securities in our universe to maximize our alpha with
    # respect to the given constraints.
    algo.order_optimal_portfolio(
        objective=objective,
        constraints=constraints
    )
